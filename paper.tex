\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{hyperref}

\usepackage[accepted]{sysml2019}

\sysmltitlerunning{Guild AI}

\begin{document}

\twocolumn[
\sysmltitle{Guild AI: Simple Reproducibility in Machine Learning}

\sysmlsetsymbol{equal}{*}

\begin{sysmlauthorlist}
\sysmlauthor{Garrett Smith}{equal,gai}
\end{sysmlauthorlist}

\sysmlaffiliation{gai}{Garrett Smith, Chicago, USA}

\sysmlcorrespondingauthor{Garrett Smith}{garrett@guild.ai}

\sysmlkeywords{Machine Learning, SysML, Guild AI}

\vskip 10pt

\begin{abstract}
  Guild AI is an open source tool for running, tracking, and comparing
  machine learning experiments. Guild helps researchers and engineers
  do their work more efficiently without imposing additional
  configuration and system requirements. By simplifying experiment
  tracking, Guild hopes to encourage more consistent reproducibility
  and improved collaboration in machine learning research.
\end{abstract}
]

\printAffiliationsAndNotice{\sysmlEqualContribution}

\section{Guild AI}

\textbf{Experiments.} Guild runs experiment trials as operating system
processes and tracks results in separate run directories. Each run
directory contains artifacts created during the trial along with
metadata such as model information, start and stop times, logs, and
run status. Run artifacts commonly include training checkpoints,
prepared data sets, generated content such as images and audio, logs,
and project source code snapshots.

\textbf{Analysis.} Guild provides facilities to analyze and compare
experiments. Users can study experiment outputs such as training and
validation loss, accuracy, required memory, batch latency as well logs
and generated files. Guild also supports detailed comparison across
experiment inputs including changes in model architecture,
hyperparameters, data sets, and source code.

\textbf{Sharing Results.} Guild helps researchers share results in
three ways ways:

\begin{itemize}[topsep=0pt, itemsep=0pt]
\item Project maintainers use \emph{Guild files}---simple YAML files
  included with project source---to document and automate project
  capabilities such as supported models, operations, hyperparameter
  defaults and search space for optimization experiments.

\item Project maintainers create Python \emph{packages} that are
  uploaded to PyPI and installed by others for reproducing results.

\item Users \emph{publish experiment results} to remote locations over
  SSH or cloud services like S3 where they are securely studied and
  compared by others.
\end{itemize}

\textbf{Command Line Interface, Visualization, API.} Guild's primary
user interface is a command line interface, which integrates
efficiently with other system tools. Guild additionally provides a
graphical, web based dashboard to explore and analyze runs and
integration with TensorBoard. Guild also exposes functionality in a
Python API for application developers.

\textbf{Cross Framework and Language Support.} Guild supports any
learning script that generates experiment results. Models may be
implemented in any language, framework, or software library.

\subsection{Reproducibility}

Guild facilitates reproducibility by automating experiments,
systematically capturing results, and providing tools for analysis and
comparison. A typical workflow in Guild is:

\begin{enumerate}[noitemsep, topsep=0pt, partopsep=0pt]
\item Run trials for a baseline model
\item Run trials for novel work
\item Compare and analyze results
\item Optionally package and distribute project code to further
  simplify reproducibility
\end{enumerate}

\subsection{Users}

Guild is used by researchers and engineers to run, track, and compare
machine learning experiments. It is useful to anyone who needs to
compare novel work to baseline results.

\subsection{Related Work and Differences}

There are several open source projects that address reproducibility in
machine learning. Prominent projects include:

\begin{itemize}[noitemsep, topsep=0pt, partopsep=0pt]
\item ModelDB \cite{modeldb}
\item MLFlow \cite{mlflow}
\item Polyaxon \cite{polyaxon}
\item datmo \cite{datmo}
\end{itemize}

Automation tools in machine learning commonly require tool-specific
changes to project source code. This generally includes adoption of a
Python API for controlling experiments, accessing hyperparameters and
logging results. Automation tools may also require additional system
software such as databases, container management systems, and job
schedulers.

Each requirement that a tool imposes on a user presents a barrier to
the goal of systematic machine learning. In some cases, researchers
may view the cost of automation in support reproducibility to
outweight the benefit.

To encourage systematic machine learning, Guild does not require
changes to user code or installation and maintenance of external
systems. Users run their training scripts without modification. For
example, an unmodified Python script \texttt{train.py} that supports
hyperparameters \texttt{n\_layers} and \texttt{lr} may be run using a
command such as:

{\footnotesize
\begin{verbatim}
$ guild run train.py n_layers=2 lr=1e-4
\end{verbatim}}

With this command, the user generates a unique experiment with the
specified hyperparameters, which can be analyzed and compared to other
trials.

Guild supports this workflow without external dependencies.

Guild additionally supports easy packaging, distribution, and
installation of research work in the support of reproducibility. To
our knowledge, no other tool provides this feature.

\section{Demonstration}

We propose an interactive demonstration that highlights the benefits
of fast, easy experiment reproduction. Throughout the session, the
presenter refers to two personas---represented visually with
placards---to help viewers maintain context for various scenario:

\begin{itemize}[topsep=0pt, itemsep=0pt]
\item \emph{Arya}. A researcher who has published state-of-the-art
  results of a novel architecture on a standard benchmark data set.
\item \emph{Clegane}. A researcher working on a survey paper that
  includes Arya's work.
\end{itemize}

While demonstrating a scenario, the presenter highlights how Guild
supports reproducibility in two areas:

\begin{itemize}[topsep=0pt, itemsep=0pt]
\item \emph{Influence}. Work that is easier to reproduce is more
  likely to influence others, other factors held constant.

\item \emph{Productivity}. Tools that support fast and easy
  reproducibility are applicable to research in general: more
  experiments generate more data, which researchers can use to advance
  their work.
\end{itemize}

\textbf{Scenarios}. The demonstration is structured flexibly to
encourage questions, input, and redirection from the audience. While
presented below as a natural sequence, scenarios are presented and
discussed in any order according to audience expectation and interest.

\begin{itemize}[topsep=0pt, itemsep=0pt]
\item \emph{Arya} uses Guild to run training and validation
  experiments, collecting results---both positive and negative---and
  announces her findings in a celebrated invited talk at SysML. Her
  work is fully reproducible when she commits her code to GitHub.

\item \emph{Clegane} conducts a survey of related work, reproducing
  published results where possible. He clones Arya's repository and
  uses Guild to reproduce her findings. He further experiments with
  changes to Arya's model and hyperparameters to build a stronger
  intuition for his summary.

\item \emph{Clegane} contacts Arya to discuss her work and answer
  questions he has based on his own experiments. He uses Guild to
  publish trials to S3 where Arya can access them.

\item \emph{Arya} pulls Clegane's results from S3 and uses Guild to
  study the differences between her results and Clegane's and uses
  this information to answer his questions.

\item \emph{Clegane}, to promote his field of study and encourage
  further research, creates an installable package that others can use
  to reproduce Arya's work along with his own findings.
\end{itemize}

\subsection{Equipment}

The presenter supplies a laptop with HDMI and brings supporting
graphical placards and other visual aids to reference during
scenarios. To avoid problems with network connectivity, the
demonstration is disconnected from the network. Demonstrations of
networking features (e.g. copying experiment results to and from S3)
are run locally over a proxy, but are nonetheless live and unmocked.

\bibliography{paper}
\bibliographystyle{sysml2019}

\end{document}
